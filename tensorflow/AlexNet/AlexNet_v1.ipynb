{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet Classification with Deep Convolutional Neural Networks\n",
    "### Advances in Neural Information Processing Systems 25 (NIPS 2012)\n",
    "#### https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks\n",
    "\n",
    "\n",
    "__Alex Krizhevsky__\n",
    "University of Toronto\n",
    "kriz@cs.utoronto.ca\n",
    "\n",
    "__Ilya Sutskever__\n",
    "University of Toronto\n",
    "ilya@cs.utoronto.ca\n",
    "\n",
    "__Geoffrey E. Hinton__\n",
    "University of Toronto\n",
    "hinton@cs.utoronto.ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "TODO: ILSRVC 2012 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet_v1(inputs = None,\n",
    "               num_classes=1000,\n",
    "               is_training=True,\n",
    "               keep_prob=0.5,\n",
    "               scope='alexnet_v1',\n",
    "               global_pool=False):\n",
    "    \n",
    "    mu = 0\n",
    "    sigma = 0.01\n",
    "    \n",
    "    # Layer 1: Convolutional. Input = 224x224x3\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(11, 11, 3, 96), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(96))\n",
    "    # Convolution\n",
    "    conv1 = tf.nn.conv2d(inputs, conv1_W, strides=[1, 4, 4, 1], padding=\"SAME\", name=\"conv1\")\n",
    "    conv1 = tf.nn.bias_add(conv1, conv1_b)\n",
    "    # Activation\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    # Local Response Normalization\n",
    "    conv1 = tf.nn.local_response_normalization(conv1, depth_radius=5.0, bias=2.0, alpha=1e-4, beta=0.75)\n",
    "    # Overlapping Max Pooling\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    \n",
    "    # Layer 2: Convolutional\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 48, 256), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(256))\n",
    "    # Convolution\n",
    "    conv2 = tf.nn.conv2d(inputs, conv2_W, strides=[1, 1, 1, 1], padding=\"SAME\", name=\"conv2\")\n",
    "    conv2 = tf.nn.bias_add(conv2, conv2_b)\n",
    "    # Activation\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    # Local Response Normalization\n",
    "    conv2 = tf.nn.local_response_normalization(conv2, depth_radius=5.0, bias=2.0, alpha=1e-4, beta=0.75)\n",
    "    # Overlapping Max Pooling\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    \n",
    "    # Layer 3: Convolutional\n",
    "    conv3_W = tf.Variable(tf.truncated_normal(shape=(3, 3, 256, 384), mean = mu, stddev = sigma))\n",
    "    conv3_b = tf.Variable(tf.zeros(384))\n",
    "    # Convolution\n",
    "    conv3 = tf.nn.conv2d(inputs, conv3_W, strides=[1, 1, 1, 1], padding=\"SAME\", name=\"conv3\")\n",
    "    conv3 = tf.nn.bias_add(conv3, conv3_b)\n",
    "    # Activation\n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "    \n",
    "    # Layer 4: Convolutional\n",
    "    conv4_W = tf.Variable(tf.truncated_normal(shape=(3, 3, 192, 384), mean = mu, stddev = sigma))\n",
    "    conv4_b = tf.Variable(tf.zeros(256))\n",
    "    # Convolution\n",
    "    conv4 = tf.nn.conv2d(inputs, conv4_W, strides=[1, 1, 1, 1], padding=\"SAME\", name=\"conv4\")\n",
    "    conv4 = tf.nn.bias_add(conv4, conv4_b)\n",
    "    # Activation\n",
    "    conv4 = tf.nn.relu(conv4)\n",
    "    \n",
    "    # Layer 5: Convolutional\n",
    "    conv5_W = tf.Variable(tf.truncated_normal(shape=(3, 3, 192, 256), mean = mu, stddev = sigma))\n",
    "    conv5_b = tf.Variable(tf.zeros(256))\n",
    "    # Convolution\n",
    "    conv5 = tf.nn.conv2d(inputs, conv5_W, strides=[1, 1, 1, 1], padding=\"SAME\", name=\"conv5\")\n",
    "    conv5 = tf.nn.bias_add(conv5, conv5_b)\n",
    "    # Activation\n",
    "    conv5 = tf.nn.relu(conv5)\n",
    "    \n",
    "    # Layer 6: Fully Connected\n",
    "    fc0 = tf.contrib.layers.flatten(conv5)\n",
    "    \n",
    "    # Layer 7: Fully Connected\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(4096, 4096), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(4096))\n",
    "    fc1 = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    \n",
    "    # Activation.\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "    # Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "\n",
    "    # Layer 8: Fully Connected. Input = 120. Output = 84.\n",
    "    fc2_W = tf.Variable(tf.truncated_normal(shape=(4096, 1000), mean = mu, stddev = sigma))\n",
    "    fc2_b = tf.Variable(tf.zeros(1000))\n",
    "    fc2 = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    # Activation.\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "    \n",
    "    # Dropout\n",
    "    fc2 = tf.nn.dropout(fc2, keep_prob)\n",
    "\n",
    "    # Layer 9: Fully Connected. Input = 84. Output = 10.\n",
    "    fc3_W = tf.Variable(tf.truncated_normal(shape=(84, 43), mean = mu, stddev = sigma))\n",
    "    fc3_b = tf.Variable(tf.zeros(43))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing\n",
    "\n",
    "TODO\n",
    "The input image dimensions vary while the network takes 224x224x3 as the input. Five random crops are taken of the image and a horizontally flipped copy is taken during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
